# ğŸ“¦ PaperDMS Common

Module partagÃ© contenant les DTOs et Events Kafka communs Ã  tous les microservices PaperDMS.

## ğŸ¯ Objectif

Ã‰viter la duplication de code entre les microservices en centralisant :
- ğŸ“¨ **Events Kafka** - DTOs pour la communication asynchrone
- ğŸ“‹ **DTOs communs** - Structures de donnÃ©es partagÃ©es
- ğŸ”§ **Utilitaires** - Classes helper communes

## ğŸ“¦ Contenu

### Events Kafka

| Event | Topic | Producteur | Consommateurs |
|-------|-------|------------|---------------|
| `DocumentUploadedEvent` | `document.uploaded` | documentService | ocrService, aiService, searchService, notificationService |
| `DocumentDeletedEvent` | `document.deleted` | documentService | searchService, notificationService |
| `DocumentUpdatedEvent` | `document.updated` | documentService | searchService |

### DTOs

_(Ã€ ajouter selon les besoins)_

## ğŸš€ Installation

### 1. Compiler et Installer Localement

```bash
cd paperdms-common
mvn clean install
```

Cela installe le JAR dans votre repository Maven local : `~/.m2/repository/`

### 2. Utiliser dans un Microservice

Ajoutez cette dÃ©pendance dans le `pom.xml` de votre microservice :

```xml
<dependency>
    <groupId>fr.smartprod.paperdms</groupId>
    <artifactId>paperdms-common</artifactId>
    <version>1.0.0</version>
</dependency>
```

## ğŸ“ Utilisation

### Producer (documentService)

```java
import fr.smartprod.paperdms.common.events.DocumentUploadedEvent;

@Service
public class DocumentUploadService {
    
    private final KafkaTemplate<String, Object> kafkaTemplate;
    
    private void publishEvent(Document document) {
        DocumentUploadedEvent event = DocumentUploadedEvent.builder()
            .documentId(document.getId())
            .sha256(document.getSha256())
            .mimeType(document.getMimeType())
            .fileSize(document.getFileSize())
            .s3Key(document.getS3Key())
            .s3Bucket(document.getS3Bucket())
            .uploadDate(document.getUploadDate())
            .uploadedBy(SecurityUtils.getCurrentUserLogin().orElse("system"))
            .build();
        
        kafkaTemplate.send("document.uploaded", document.getId().toString(), event);
        log.info("Published document.uploaded event: {}", event);
    }
}
```

### Consumer (ocrService)

```java
import fr.smartprod.paperdms.common.events.DocumentUploadedEvent;

@Service
public class OcrConsumer {
    
    private final Logger log = LoggerFactory.getLogger(OcrConsumer.class);
    
    @KafkaListener(
        topics = "document.uploaded", 
        groupId = "ocr-service",
        containerFactory = "kafkaListenerContainerFactory"
    )
    public void handleDocumentUploaded(DocumentUploadedEvent event) {
        log.info("Received document.uploaded event: {}", event);
        
        // Filtrer uniquement les PDFs et images
        if (isPdfOrImage(event.getMimeType())) {
            // TÃ©lÃ©charger depuis S3
            byte[] content = s3Service.download(event.getS3Bucket(), event.getS3Key());
            
            // Extraire le texte
            String extractedText = ocrService.extractText(content, event.getMimeType());
            
            // Sauvegarder
            documentRepository.updateExtractedText(event.getDocumentId(), extractedText);
            
            log.info("OCR completed for document: {}", event.getDocumentId());
        }
    }
    
    private boolean isPdfOrImage(String mimeType) {
        return mimeType != null && 
               (mimeType.equals("application/pdf") || mimeType.startsWith("image/"));
    }
}
```

### Consumer (aiService)

```java
import fr.smartprod.paperdms.common.events.DocumentUploadedEvent;

@Service
public class AutoTaggingConsumer {
    
    @KafkaListener(topics = "document.uploaded", groupId = "ai-service")
    public void handleDocumentUploaded(DocumentUploadedEvent event) {
        log.info("Auto-tagging document: {}", event.getDocumentId());
        
        // RÃ©cupÃ©rer le texte extrait par OCR
        String text = documentRepository.findExtractedText(event.getDocumentId());
        
        // Analyser avec IA
        List<String> suggestedTags = aiService.suggestTags(
            text, 
            event.getFileName(), 
            event.getMimeType()
        );
        
        // Appliquer les tags
        tagService.applyTags(event.getDocumentId(), suggestedTags);
    }
}
```

## ğŸ”§ DÃ©veloppement

### Ajouter un Nouvel Event

1. CrÃ©er la classe dans `src/main/java/.../events/`
2. ImplÃ©menter `Serializable`
3. Ajouter les annotations Jackson pour JSON
4. Documenter le producteur et les consommateurs
5. Compiler : `mvn clean install`
6. Mettre Ã  jour ce README

### Versioning

Suivez le [Semantic Versioning](https://semver.org/) :

- **1.0.0** â†’ **1.0.1** : Bug fix, compatible
- **1.0.0** â†’ **1.1.0** : Nouvelle fonctionnalitÃ©, compatible
- **1.0.0** â†’ **2.0.0** : Breaking change, incompatible

### Tests

```bash
# Compiler
mvn clean compile

# Tester
mvn test

# Package
mvn package
```

## ğŸ“š Structure du Projet

```
paperdms-common/
â”œâ”€â”€ pom.xml
â”œâ”€â”€ README.md
â””â”€â”€ src/
    â””â”€â”€ main/
        â””â”€â”€ java/
            â””â”€â”€ fr/smartprod/paperdms/common/
                â”œâ”€â”€ events/
                â”‚   â”œâ”€â”€ DocumentUploadedEvent.java
                â”‚   â”œâ”€â”€ DocumentDeletedEvent.java
                â”‚   â””â”€â”€ DocumentUpdatedEvent.java
                â”œâ”€â”€ dto/
                â”‚   â””â”€â”€ (DTOs communs)
                â””â”€â”€ util/
                    â””â”€â”€ (Classes utilitaires)
```

## ğŸ”„ Workflow CI/CD

### Build Local

```bash
mvn clean install
```

### Build CI (GitHub Actions / GitLab CI)

```yaml
- name: Build paperdms-common
  run: |
    cd paperdms-common
    mvn clean install
```

### Publish to Nexus (Production)

```bash
mvn deploy
```

## ğŸ“‹ Checklist d'Utilisation

### Pour Ajouter dans un Nouveau Service

- [ ] Ajouter la dÃ©pendance dans `pom.xml`
- [ ] Importer les events nÃ©cessaires
- [ ] Configurer Kafka dans `application.yml`
- [ ] CrÃ©er les consumers/producers
- [ ] Tester la communication

## ğŸ†˜ DÃ©pannage

### Erreur: "Cannot resolve paperdms-common"

**Solution** : Installer le module dans votre repo local
```bash
cd paperdms-common
mvn clean install
```

### Erreur de SÃ©rialisation JSON

**Solution** : VÃ©rifier que Jackson est configurÃ©
```yaml
spring:
  kafka:
    producer:
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
    consumer:
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "fr.smartprod.paperdms.common.events"
```

### Event Non ReÃ§u

**Solution** : VÃ©rifier les topics et group IDs
```bash
# Lister les topics
kafka-topics --bootstrap-server localhost:9092 --list

# Consumer console
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic document.uploaded --from-beginning
```

## ğŸ“ Bonnes Pratiques

âœ… **Ã€ FAIRE**
- Toujours incrÃ©menter la version aprÃ¨s modification
- Documenter chaque event (producteur, consommateurs, topic)
- Utiliser le builder pattern
- ImplÃ©menter `toString()`, `equals()`, `hashCode()`
- Tester la sÃ©rialisation/dÃ©sÃ©rialisation

âŒ **Ã€ Ã‰VITER**
- Ne pas modifier les events existants (crÃ©er une v2 si besoin)
- Ne pas inclure de logique mÃ©tier dans les events
- Ne pas oublier `serialVersionUID`

## ğŸ“ Support

En cas de problÃ¨me avec le module common :
1. VÃ©rifier que la version est Ã  jour
2. Consulter la Javadoc gÃ©nÃ©rÃ©e
3. VÃ©rifier les logs Kafka

---

**Module Common = Code DRY + Communication StandardisÃ©e ! ğŸ“¦**

Version: 1.0.0
